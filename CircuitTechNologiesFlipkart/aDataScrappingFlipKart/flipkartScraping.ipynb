{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rw9V1AikNmdv"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtgY26srOH2Z"
      },
      "outputs": [],
      "source": [
        "URL = 'https://www.flipkart.com/search?q=smart+lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=6'\n",
        "API_KEY = '53fde5daee9e3fd8b128656faaf77e49'\n",
        "\n",
        "# ScraperAPI setup\n",
        "api_url = f'http://api.scraperapi.com?api_key={API_KEY}&url={URL}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vGwLVAZOPTE"
      },
      "outputs": [],
      "source": [
        "# HTTP Request\n",
        "webpage = requests.get(api_url)\n",
        "# Soup Object containiang all data\n",
        "soup = BeautifulSoup(webpage.content, \"html.parser\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OuMYAfIPL7a"
      },
      "outputs": [],
      "source": [
        "links = soup.find_all(\"a\", attrs={'class':'wjcEIp'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsRNjPNXS2ff",
        "outputId": "dec2ab3c-086a-45cf-ec3b-6d3bfe4e6edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34\n"
          ]
        }
      ],
      "source": [
        "print(len(links))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L9nd4PkQe07",
        "outputId": "b9a53385-a9cf-453a-f529-26edf0e16a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to product_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Initialize the list to store product data\n",
        "product_data = []\n",
        "\n",
        "for i in range(len(links)):\n",
        "    try:\n",
        "        link = links[i].get('href')\n",
        "        product_link_full = \"https://www.flipkart.com\" + link\n",
        "        product_url = f'http://api.scraperapi.com?api_key={API_KEY}&url={product_link_full}'\n",
        "\n",
        "        # Request product page\n",
        "        product_webpage = requests.get(product_url)\n",
        "        product_soup = BeautifulSoup(product_webpage.content, \"html.parser\")\n",
        "\n",
        "        # Extract details with error handling\n",
        "        try:\n",
        "            title = product_soup.find(\"span\", attrs={\"class\": 'VU-ZEz'}).text.strip()\n",
        "        except AttributeError:\n",
        "            title = \"0\"\n",
        "\n",
        "        try:\n",
        "            brand = product_soup.find(\"td\", attrs={\"class\": 'Izz52n col col-9-12'}).text.strip()\n",
        "        except AttributeError:\n",
        "            brand = \"0\"\n",
        "\n",
        "        try:\n",
        "            price = product_soup.find(\"div\", attrs={\"class\": 'Nx9bqj CxhGGd'}).text.strip()\n",
        "        except AttributeError:\n",
        "            price = \"0\"\n",
        "\n",
        "        try:\n",
        "            rating = product_soup.find(\"div\", attrs={\"class\": 'XQDdHH'}).text.strip()\n",
        "        except AttributeError:\n",
        "            rating = \"0\"\n",
        "\n",
        "        # Handle rating count and review count\n",
        "        try:\n",
        "            rating_count_div = product_soup.find(\"div\", attrs={\"class\": 'row j-aW8Z'})\n",
        "            rating_count = rating_count_div.find(\"span\").text.strip() if rating_count_div else \"0\"\n",
        "\n",
        "            # Find the sibling for review count if rating_count_div exists\n",
        "            if rating_count_div:\n",
        "                review_count_div = rating_count_div.find_next_sibling(\"div\", attrs={\"class\": 'row j-aW8Z'})\n",
        "                review_count = review_count_div.find(\"span\").text.strip() if review_count_div else \"0\"\n",
        "            else:\n",
        "                review_count = \"0\"\n",
        "        except AttributeError:\n",
        "            rating_count = \"0\"\n",
        "            review_count = \"0\"\n",
        "\n",
        "        # Store product data\n",
        "        product_data.append({\n",
        "            \"Title\": title,\n",
        "            \"Brand\": brand,\n",
        "            \"Price\": price,\n",
        "            \"Rating\": rating,\n",
        "            \"Rating Count\": rating_count,\n",
        "            \"Review Count\": review_count,\n",
        "            \"URL\": product_link_full\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing product at index {i}: {e}\")\n",
        "\n",
        "# Save data to a CSV file\n",
        "df = pd.DataFrame(product_data)\n",
        "df.to_csv(\"/content/csvfiles/product_data6.csv\", index=False)\n",
        "print(\"Data saved to product_data.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
