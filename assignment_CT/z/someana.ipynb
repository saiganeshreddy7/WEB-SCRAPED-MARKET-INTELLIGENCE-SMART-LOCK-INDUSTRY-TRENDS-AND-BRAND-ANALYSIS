{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Specify the path where your CSV files are located\n",
    "# Adjust the path pattern according to your file naming\n",
    "csv_files = glob.glob('/Users/saiganeshreddykodekandla/Documents/projects/circuitTechnologies/assignment_CT/from_amazon/scrapping_files/csvFiles/*.csv')  # For example, 'data/*.csv'\n",
    "\n",
    "# List of CSV files in the order you want to merge them\n",
    "# Replace these with the actual file names\n",
    "ordered_files = ['product_data1.csv', 'product_data2.csv', 'product_data3.csv','product_data4.csv','product_data5.csv','product_data6.csv','product_data7.csv']  # Adjust this list as needed\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the ordered file names and read each into a DataFrame\n",
    "for file in ordered_files:\n",
    "    df = pd.read_csv(f'/Users/saiganeshreddykodekandla/Documents/projects/circuitTechnologies/assignment_CT/from_amazon/scrapping_files/csvFiles/{file}')\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate the DataFrames along the rows (axis=0)\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('/Users/saiganeshreddykodekandla/Documents/projects/circuitTechnologies/assignment_CT/z/merged_file.csv', index=False)\n",
    "\n",
    "print(\"Merged file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./merged_file.csv')\n",
    "\n",
    "# Keep only the 'Product Title' column\n",
    "df_filtered = df[['Product Title']]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "df_filtered.to_csv('/Users/saiganeshreddykodekandla/Documents/projects/circuitTechnologies/assignment_CT/product_titles.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-string values in 'Product Title' column converted to strings and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./product_titles.csv')\n",
    "\n",
    "# Convert all values in the 'Product Title' column to strings\n",
    "df['Product Title'] = df['Product Title'].astype(str)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('corrected_product_titles.csv', index=False)\n",
    "\n",
    "print(\"Non-string values in 'Product Title' column converted to strings and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in the 'Product Title' column are strings.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./cleaned_product_titles.csv')\n",
    "\n",
    "# Check if all values in the 'Product Title' column are strings\n",
    "are_all_strings = df['Product Title'].apply(lambda x: isinstance(x, str))\n",
    "\n",
    "# Print the result\n",
    "if are_all_strings.all():\n",
    "    print(\"All values in the 'Product Title' column are strings.\")\n",
    "else:\n",
    "    print(\"There are non-string values in the 'Product Title' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank column created based on unique product titles and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./corrected_product_titles.csv')\n",
    "\n",
    "# Create a new column 'Rank' initialized with NaN\n",
    "df['Rank'] = None\n",
    "\n",
    "# Create a set to track unique product titles\n",
    "seen_titles = set()\n",
    "rank = 1  # Starting rank\n",
    "\n",
    "# Loop through the 'Product Title' column using items()\n",
    "for index, title in df['Product Title'].items():\n",
    "    if title not in seen_titles:  # Check if the title is unique\n",
    "        df.at[index, 'Rank'] = rank  # Assign the rank\n",
    "        seen_titles.add(title)  # Add the title to the set\n",
    "        rank += 1  # Increment the rank for the next unique title\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('ranked_product_titles.csv', index=False)\n",
    "\n",
    "print(\"Rank column created based on unique product titles and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates and specified rows removed successfully. Saved to 'cleaned_product_titles.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./ranked_product_titles.csv')\n",
    "\n",
    "# Remove rows where 'Product Title' is NaN or 0\n",
    "df = df[~df['Product Title'].isna() & (df['Product Title'] != 0)]\n",
    "\n",
    "# Remove duplicate entries in the 'Product Title' column, keeping the first occurrence\n",
    "df = df.drop_duplicates(subset='Product Title', keep='first')\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('cleaned_product_titles.csv', index=False)\n",
    "\n",
    "print(\"Duplicates and specified rows removed successfully. Saved to 'cleaned_product_titles.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product titles converted to lowercase and saved successfully to 'lowercase_product_titles.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./cleaned_product_titles.csv')\n",
    "\n",
    "# Convert all values in the 'Product Title' column to lowercase\n",
    "df['Product Title'] = df['Product Title'].str.lower()\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('lowercase_product_titles.csv', index=False)\n",
    "\n",
    "print(\"Product titles converted to lowercase and saved successfully to 'lowercase_product_titles.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank column added to FinalFile and saved successfully to 'FinalFile_with_rank.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "file1 = pd.read_csv('./mainfile.csv')  # File containing Product Title and Rank\n",
    "file2 = pd.read_csv('/Users/saiganeshreddykodekandla/Documents/projects/circuitTechnologies/assignment_CT/from_amazon/dataCleaningFiles/finalFiles/FinalFile.csv')  # File to which Rank will be added\n",
    "\n",
    "# Merge the two DataFrames on the 'Product_Title' and 'Product Title' columns\n",
    "# Note: You may need to adjust column names to match exactly\n",
    "merged_df = pd.merge(file2, file1, how='left', left_on='Product_Title', right_on='Product Title')\n",
    "\n",
    "# Rename the rank column if necessary\n",
    "merged_df.rename(columns={'Rank': 'Rank'}, inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "merged_df.to_csv('FinalFile_with_rank.csv', index=False)\n",
    "\n",
    "print(\"Rank column added to FinalFile and saved successfully to 'FinalFile_with_rank.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Average_Best_Seller_Rank' dropped successfully and saved to 'FinalFile_dropped_column.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./FinalFileWithRank.csv')\n",
    "\n",
    "# Drop the column 'Average_Best_Seller_Rank'\n",
    "df = df.drop(columns=['Product Title'])\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('finalFileWithRankApperance.csv', index=False)\n",
    "\n",
    "print(\"Column 'Average_Best_Seller_Rank' dropped successfully and saved to 'FinalFile_dropped_column.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Rank' moved successfully and saved to 'FinalFile_reordered_columns.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./finalFileWithRankApperance.csv')\n",
    "\n",
    "# Define the new column order\n",
    "new_column_order = ['Brand', 'Price', 'Rating', 'Rating_Count', 'Rank', 'Product_Title', 'Product_URL']\n",
    "\n",
    "# Reorder the DataFrame based on the new column order\n",
    "df = df[new_column_order]\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('FinalFileRO.csv', index=False)\n",
    "\n",
    "print(\"Column 'Rank' moved successfully and saved to 'FinalFile_reordered_columns.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Rank' converted to integers and saved to 'FinalFile_rank_converted.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/saiganeshreddykodekandla/Documents/projects/circuitTechnologies/assignment_CT/z/FinalFileRO.csv')\n",
    "\n",
    "# Convert the 'Rank' column to integers, handling non-integer values by coercing them to NaN\n",
    "df['Rank_'] = pd.to_numeric(df['Rank_'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('/Users/saiganeshreddykodekandla/Documents/projects/circuitTechnologies/assignment_CT/z/FinalFileRO.csv', index=False)\n",
    "\n",
    "print(\"Column 'Rank' converted to integers and saved to 'FinalFile_rank_converted.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https:', '', 'amazon.in', 'nandati-Invisible-Specially-Designed-Wardrobe', 'dp', 'B0C6QXDHBY', 'ref=sr_1_197?crid=3MNJ4J5A0A3FY&dib=eyJ2IjoiMSJ9._zUEnmCrdcn2sDDKHKoIEPeC2s879JzSb5Y77YAvtEkD0esIjD4_S1O5KVXGGjl0nakTpvKY1Q4br74GBprGoOXCi9LsulIb0oaxVlv1SURqhugfwFZw5_UYy0x3JmwqJ9HFP4TYg4UyF-a_-jV2E8RUAqz-DLj8_fUX2dI4X1dWC_slsX0wYt0iDAcaBwtDxhcvz6OvRC5a2svrucVKsJCcfRpyTm6J5mjwYyQhCDzBN35FCgDn2plQD28TkHvmfU72T7dGYtp82NHql6y_xcKlTKAEfqWTI6qObC2OqAA.TiwjC_wFS_jS9o8-GWN9I8-9Nm0Yqq3SFx9hsBg0pGI&dib_tag=se&keywords=smart+lock&qid=1730095184&sprefix=smart+lock%2Caps%2C209&sr=8-197']\n",
      "['h', 't', 't', 'p', 's', ':', '/', '/', 'a', 'm', 'a', 'z', 'o', 'n', '.', 'i', 'n', '/', 'n', 'a', 'n', 'd', 'a', 't', 'i', '-', 'I', 'n', 'v', 'i', 's', 'i', 'b', 'l', 'e', '-', 'S', 'p', 'e', 'c', 'i', 'a', 'l', 'l', 'y', '-', 'D', 'e', 's', 'i', 'g', 'n', 'e', 'd', '-', 'W', 'a', 'r', 'd', 'r', 'o', 'b', 'e', '/', 'd', 'p', '/', 'B', '0', 'C', '6', 'Q', 'X', 'D', 'H', 'B', 'Y', '/', 'r', 'e', 'f', '=', 's', 'r', '_', '1', '_', '1', '9', '7', '?', 'c', 'r', 'i', 'd', '=', '3', 'M', 'N', 'J', '4', 'J', '5', 'A', '0', 'A', '3', 'F', 'Y', '&', 'd', 'i', 'b', '=', 'e', 'y', 'J', '2', 'I', 'j', 'o', 'i', 'M', 'S', 'J', '9', '.', '_', 'z', 'U', 'E', 'n', 'm', 'C', 'r', 'd', 'c', 'n', '2', 's', 'D', 'D', 'K', 'H', 'K', 'o', 'I', 'E', 'P', 'e', 'C', '2', 's', '8', '7', '9', 'J', 'z', 'S', 'b', '5', 'Y', '7', '7', 'Y', 'A', 'v', 't', 'E', 'k', 'D', '0', 'e', 's', 'I', 'j', 'D', '4', '_', 'S', '1', 'O', '5', 'K', 'V', 'X', 'G', 'G', 'j', 'l', '0', 'n', 'a', 'k', 'T', 'p', 'v', 'K', 'Y', '1', 'Q', '4', 'b', 'r', '7', '4', 'G', 'B', 'p', 'r', 'G', 'o', 'O', 'X', 'C', 'i', '9', 'L', 's', 'u', 'l', 'I', 'b', '0', 'o', 'a', 'x', 'V', 'l', 'v', '1', 'S', 'U', 'R', 'q', 'h', 'u', 'g', 'f', 'w', 'F', 'Z', 'w', '5', '_', 'U', 'Y', 'y', '0', 'x', '3', 'J', 'm', 'w', 'q', 'J', '9', 'H', 'F', 'P', '4', 'T', 'Y', 'g', '4', 'U', 'y', 'F', '-', 'a', '_', '-', 'j', 'V', '2', 'E', '8', 'R', 'U', 'A', 'q', 'z', '-', 'D', 'L', 'j', '8', '_', 'f', 'U', 'X', '2', 'd', 'I', '4', 'X', '1', 'd', 'W', 'C', '_', 's', 'l', 's', 'X', '0', 'w', 'Y', 't', '0', 'i', 'D', 'A', 'c', 'a', 'B', 'w', 't', 'D', 'x', 'h', 'c', 'v', 'z', '6', 'O', 'v', 'R', 'C', '5', 'a', '2', 's', 'v', 'r', 'u', 'c', 'V', 'K', 's', 'J', 'C', 'c', 'f', 'R', 'p', 'y', 'T', 'm', '6', 'J', '5', 'm', 'j', 'w', 'Y', 'y', 'Q', 'h', 'C', 'D', 'z', 'B', 'N', '3', '5', 'F', 'C', 'g', 'D', 'n', '2', 'p', 'l', 'Q', 'D', '2', '8', 'T', 'k', 'H', 'v', 'm', 'f', 'U', '7', '2', 'T', '7', 'd', 'G', 'Y', 't', 'p', '8', '2', 'N', 'H', 'q', 'l', '6', 'y', '_', 'x', 'c', 'K', 'l', 'T', 'K', 'A', 'E', 'f', 'q', 'W', 'T', 'I', '6', 'q', 'O', 'b', 'C', '2', 'O', 'q', 'A', 'A', '.', 'T', 'i', 'w', 'j', 'C', '_', 'w', 'F', 'S', '_', 'j', 'S', '9', 'o', '8', '-', 'G', 'W', 'N', '9', 'I', '8', '-', '9', 'N', 'm', '0', 'Y', 'q', 'q', '3', 'S', 'F', 'x', '9', 'h', 's', 'B', 'g', '0', 'p', 'G', 'I', '&', 'd', 'i', 'b', '_', 't', 'a', 'g', '=', 's', 'e', '&', 'k', 'e', 'y', 'w', 'o', 'r', 'd', 's', '=', 's', 'm', 'a', 'r', 't', '+', 'l', 'o', 'c', 'k', '&', 'q', 'i', 'd', '=', '1', '7', '3', '0', '0', '9', '5', '1', '8', '4', '&', 's', 'p', 'r', 'e', 'f', 'i', 'x', '=', 's', 'm', 'a', 'r', 't', '+', 'l', 'o', 'c', 'k', '%', '2', 'C', 'a', 'p', 's', '%', '2', 'C', '2', '0', '9', '&', 's', 'r', '=', '8', '-', '1', '9', '7']\n"
     ]
    }
   ],
   "source": [
    "url =  'https://amazon.in/nandati-Invisible-Specially-Designed-Wardrobe/dp/B0C6QXDHBY/ref=sr_1_197?crid=3MNJ4J5A0A3FY&dib=eyJ2IjoiMSJ9._zUEnmCrdcn2sDDKHKoIEPeC2s879JzSb5Y77YAvtEkD0esIjD4_S1O5KVXGGjl0nakTpvKY1Q4br74GBprGoOXCi9LsulIb0oaxVlv1SURqhugfwFZw5_UYy0x3JmwqJ9HFP4TYg4UyF-a_-jV2E8RUAqz-DLj8_fUX2dI4X1dWC_slsX0wYt0iDAcaBwtDxhcvz6OvRC5a2svrucVKsJCcfRpyTm6J5mjwYyQhCDzBN35FCgDn2plQD28TkHvmfU72T7dGYtp82NHql6y_xcKlTKAEfqWTI6qObC2OqAA.TiwjC_wFS_jS9o8-GWN9I8-9Nm0Yqq3SFx9hsBg0pGI&dib_tag=se&keywords=smart+lock&qid=1730095184&sprefix=smart+lock%2Caps%2C209&sr=8-197'\n",
    "\n",
    "\n",
    "# count = 0 \n",
    "# list1 = []\n",
    "# for i in url:\n",
    "#     y = ('/')\n",
    "#     if i == y:\n",
    "#         count += 1\n",
    "#         print(count)\n",
    "#         if count == 5:\n",
    "#             list1.append(i)\n",
    "#             if i == y:\n",
    "#                 break\n",
    "\n",
    "# print(list1)\n",
    "           \n",
    "x = url.split('/')\n",
    "print(x)\n",
    "\n",
    "list2 = [] \n",
    "            \n",
    "for i in url:\n",
    "    list2.append(i)\n",
    "    \n",
    "print(list2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
